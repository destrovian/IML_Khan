{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 1b Hand-In\n",
    "\n",
    "Learning based on linear regression (I think)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.linear_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate sample data\n",
    "\n",
    "Import the sample data as numpy array. Extract y & x to make prediction with\n",
    "sklearn."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('train.csv', delimiter=',', skiprows=1)  # n x [id, y, x1, ... x5] (skipping the title)\n",
    "y = train_data[:,1]  # extrac y from second column\n",
    "xs = train_data[:,2:]  # extract x1, ... x5 from the last 5 columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 21 weights.\n",
    "first we need it normal\n",
    "then quadratic\n",
    "then exponential\n",
    "then in cosine(x)\n",
    "and then as a bias of 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "xs_squared = xs**2\n",
    "xs_exp = np.exp(xs)\n",
    "xs_cos = np.cos(xs)\n",
    "bias = np.ones_like(y)[:, np.newaxis]  # one-vector with same height as y, but in matrix form\n",
    "\n",
    "xs_trans = np.concatenate([xs, xs_squared, xs_exp, xs_cos, bias],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets define some classifiers in order to check for the best one:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'sklearn' has no attribute 'linear_model'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3fd216da98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#sklearn.linear_model.TheilSenRegressor(max_iter=1024,tol=1e-16),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#sklearn.linear_model.RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 100], fit_intercept=False),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     sklearn.linear_model.LinearRegression(fit_intercept=False)]\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn' has no attribute 'linear_model'"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    #sklearn.svm.SVR(kernel='linear', gamma='auto',tol=1e-14),\n",
    "    #sklearn.linear_model.SGDRegressor(),\n",
    "    #sklearn.linear_model.BayesianRidge(tol=1e-16, n_iter=512),\n",
    "    #sklearn.linear_model.LassoLars(max_iter=500),\n",
    "    #sklearn.linear_model.ARDRegression(tol=1e-8, n_iter=1000),\n",
    "    #sklearn.linear_model.PassiveAggressiveRegressor(),\n",
    "    #sklearn.linear_model.TheilSenRegressor(max_iter=1024,tol=1e-16),\n",
    "    #sklearn.linear_model.RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 100], fit_intercept=False),\n",
    "    sklearn.linear_model.LinearRegression(fit_intercept=False)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's predict some stuff :D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using LinearRegression(fit_intercept=False)  (on the TRAINING DATA)\n51.11835577424796 (ASE)\n0.03564105329281397 (Score)\n\nUsing RidgeCV(alphas=array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+02]),\n        fit_intercept=False)  (on the TRAINING DATA)\n51.78715602297388 (ASE)\n0.010241854083643975 (Score)\n\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    clf.fit(xs_trans,y)\n",
    "    print(f\"Using {clf}  (on the TRAINING DATA)\\n{np.linalg.norm(y-clf.predict(xs_trans))} (ASE)\\n{clf.score(xs_trans,y)} (Score)\\n\")\n",
    "    np.savetxt(\"REEEEE%s.csv\" %clf, clf.coef_ , delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## w/o outlier detection\n",
    "best SVR:\n",
    "51.576009071282854\n",
    "\n",
    "best ARD:\n",
    "51.51338746231246\n",
    "\n",
    "## with outlier detection\n",
    "best svr:\n",
    "51.060581006701"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}