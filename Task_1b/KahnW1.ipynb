{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 1b Hand-In\n",
    "\n",
    "Learning based on linear regression (I think)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "from sklearn import neighbors\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate sample data\n",
    "\n",
    "Import the sample data as numpy array. Reshape the data to fit d=13\n",
    "and n= to whatever the data set says. Extract y to make prediction with\n",
    "sklearn."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700,)\n",
      "(700, 5)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.genfromtxt('train.csv', delimiter=',')\n",
    "train_data=np.delete(train_data,0,0)\n",
    "train_data=np.delete(train_data,0,1)\n",
    "y = train_data[:,0]\n",
    "train_data=np.delete(train_data,0,1)\n",
    "\n",
    "print(y.shape)\n",
    "print(train_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets try to get rid of some outliers and see if this changes the final error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "data_mean, data_std = np.mean(train_data), np.std(train_data)\n",
    "\n",
    "lof = sklearn.neighbors.LocalOutlierFactor(n_neighbors= 60)\n",
    "yhat = lof.fit_predict(train_data)\n",
    "\n",
    "mask = yhat != -1\n",
    "#train_data, y = train_data[mask,:], y[mask]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets try to delete outliers from the dataset in order to have a better\n",
    "estimate of the overall data. (but screw this cause apparently we dont need it)\n",
    "instead the data has to be extended according to the given equation in the exercise.\n",
    "therefore the final test_data matrix shall have shape 700,21 for which we optimize\n",
    "the 21 weights.\n",
    "first we need it normal\n",
    "then quadratic\n",
    "then exponential\n",
    "then in cosine(x)\n",
    "and then as a bias of 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_data_quad = train_data**2\n",
    "train_data_exp = np.exp(train_data)\n",
    "train_data_cos = np.cos(train_data)\n",
    "bias = np.ones([700,1])\n",
    "\n",
    "train_total = np.append(train_data,train_data_quad,axis=1)\n",
    "train_total = np.append(train_total,train_data_exp,axis=1)\n",
    "train_total = np.append(train_total,train_data_cos,axis=1)\n",
    "train_total = np.append(train_total,bias,axis=1)\n",
    "#print(train_total.shape)\n",
    "#print(train_total[:,[0,5,10,15]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets define some classifiers in order to check for the best one:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    #sklearn.svm.SVR(kernel='linear', gamma='auto',tol=1e-14),\n",
    "    #sklearn.linear_model.SGDRegressor(),\n",
    "    #sklearn.linear_model.BayesianRidge(tol=1e-16, n_iter=512),\n",
    "    #sklearn.linear_model.LassoLars(max_iter=500),\n",
    "    #sklearn.linear_model.ARDRegression(tol=1e-8, n_iter=1000),\n",
    "    #sklearn.linear_model.PassiveAggressiveRegressor(),\n",
    "    #sklearn.linear_model.TheilSenRegressor(max_iter=1024,tol=1e-16),\n",
    "    sklearn.linear_model.LinearRegression(fit_intercept=False)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now let's predict some stuff :D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LinearRegression(fit_intercept=False) the ASE of 51.118355774247185 on the TRAINING DATA \n",
      "\n",
      "[   87.19891672   -67.27010868    28.53822969   158.07550393\n",
      "  -819.69642943   200.04958806  -393.54175644  1953.26215983\n",
      "  -523.63288818  1518.93422147   -86.60565699    65.34027498\n",
      "   -30.99213085  -155.77167729   822.10809654   327.10998798\n",
      "  -737.64020342  3890.67031158 -1211.22831197  3799.82175097\n",
      " -6689.18957843]\n"
     ]
    }
   ],
   "source": [
    "temp= np.zeros([21,1])\n",
    "for item in classifiers:\n",
    "    clf = item\n",
    "    clf.fit(train_total,y)\n",
    "    predict_train = clf.predict(train_total)\n",
    "    #predict_test = clf.predict(train_total)\n",
    "    #print(clf.score(train_data,predict))\n",
    "    print(\"Using %(n)s the ASE of %(s)s on the TRAINING DATA\" % {'n': item, 's': np.linalg.norm(y-predict_train)}, \"\\n\")\n",
    "    #print(\"The mathematical MSE %s is: \" %np.linalg.norm(y_math-predict_test))\n",
    "    #print(\"The Score for the train data is %s\" % {'s': clf.score(train_total,predict_train)}, \"\\n\")\n",
    "    print(clf.coef_)\n",
    "\n",
    "    #result = pd.DataFrame(temp, columns=title)\n",
    "    #print(result)\n",
    "    np.savetxt(\"REEEE%s.csv\" %item, clf.coef_ , delimiter=\",\")\n",
    "    #result.to_csv(\"REEE%s.csv\" %item, header=True, index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#np.savetxt(\"REEE_1.csv\", result, delimiter=\",\",fmt='%f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## w/o outlier detection\n",
    "best SVR:\n",
    "51.576009071282854\n",
    "\n",
    "best ARD:\n",
    "51.51338746231246\n",
    "\n",
    "## with outlier detection\n",
    "best svr:\n",
    "51.060581006701"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}