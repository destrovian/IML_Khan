{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 1 Hand-In\n",
    "\n",
    "Learning based on linear regression (I think)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "from sklearn import neighbors\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate sample data\n",
    "\n",
    "Import the sample data as numpy array. Reshape the data to fit d=13\n",
    "and n= to whatever the data set says. Extract y to make prediction with\n",
    "sklearn."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(150, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "train_data = np.genfromtxt('train.csv', delimiter=',')\n",
    "train_data=np.delete(train_data,0,0)\n",
    "y = train_data[:,0]\n",
    "train_data=np.delete(train_data,0,1)\n",
    "\n",
    "print(train_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets try to delete outliers from the dataset in order to have a better\n",
    "estimate of the overall data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "#data_mean, data_std = np.mean(train_data), np.std(train_data)\n",
    "\n",
    "#lof = sklearn.neighbors.LocalOutlierFactor(n_neighbors= 60)\n",
    "#yhat = lof.fit_predict(train_data)\n",
    "\n",
    "#mask = yhat != -1\n",
    "#train_data, y = train_data[mask,:], y[mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the training data has to be k-fold split. this is done using\n",
    "sklearn.model_selection.KFold on the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using 0.1 and the ASE of 5.646763676830153 on the TRAINING DATA \n",
      "\n",
      "Using 1 and the ASE of 5.658238969785659 on the TRAINING DATA \n",
      "\n",
      "Using 10 and the ASE of 5.670512717218744 on the TRAINING DATA \n",
      "\n",
      "Using 100 and the ASE of 5.887396173877172 on the TRAINING DATA \n",
      "\n",
      "Using 200 and the ASE of 5.991401479375544 on the TRAINING DATA \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "result = np.zeros([5,1])\n",
    "gamma = [0.1,1,10,100,200]\n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "for item in gamma:\n",
    "    #for item_1 in solver:\n",
    "    reg_par = item\n",
    "    #sol_1 = item_1\n",
    "    predict_train = sklearn.model_selection.cross_val_predict(sklearn.linear_model.Ridge(alpha=reg_par,max_iter=4096,tol=1e-9,solver='auto'), train_data, y, cv=10)\n",
    "    temp = sklearn.metrics.mean_squared_error(y, predict_train, squared=False)\n",
    "    print(\"Using %(n)s and the ASE of %(s)s on the TRAINING DATA\" % {'n': reg_par, 's': temp}, \"\\n\")\n",
    "    result[i]= temp\n",
    "    i=i+1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "save the results:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "np.savetxt(\"REEE_1.csv\", result, delimiter=\",\",fmt='%f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "13.64882\n",
    "13.85238\n",
    "16.58705\n",
    "27.54864\n",
    "30.29100\n",
    "\n",
    "[[27.21421409], [25.785742  ], [22.53590906], [27.62358544], [30.08320505]]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}