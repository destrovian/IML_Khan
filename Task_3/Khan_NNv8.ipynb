{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sklearn.preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from scipy import special\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import class_weight\n",
    "import keras\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Layer\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(69) #fixing seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train_split = df_train['Sequence'].apply(lambda x: pd.Series(list(x))) #splits the 4 mutators into individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test_split = df_test['Sequence'].apply(lambda x: pd.Series(list(x))) #splits the 4 mutators into individual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define universe of possible input values\n",
    "mutators = 'ACDEFGHIKLMNPQRSTUVWY' #abcdefghijklmnopqrstuvwxyz\n",
    "#bjoqxz <-- these letters are missing\n",
    "\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(mutators))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(mutators))\n",
    "\n",
    "# integer encode input data\n",
    "#integer_encoded = [char_to_int[item] for item in df_letters[0]]\n",
    "\n",
    "# Define the label for the NN which is the activation of the protein.\n",
    "labels = df_train['Active'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining some constants.\n",
    "\n",
    "NUM_MUTATORS = len(mutators)\n",
    "\n",
    "DF_TRAIN_SIZE = len(df_train.index)\n",
    "DF_TEST_SIZE = len(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_onehot = np.zeros((DF_TRAIN_SIZE, NUM_MUTATORS*4))\n",
    "\n",
    "#We convert the mutators into the OneHot representation.\n",
    "for i in range(0,4):\n",
    "    for j in range(0, DF_TRAIN_SIZE):\n",
    "        temp = char_to_int[df_train_split.loc[j,i]]\n",
    "        df_train_onehot[j, i*NUM_MUTATORS + temp] = 1      #binary representation of the letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same with the test dataframe\n",
    "df_test_onehot = np.zeros((DF_TEST_SIZE, NUM_MUTATORS*4))\n",
    "\n",
    "for i in range(0,4):\n",
    "    for j in range(0, DF_TEST_SIZE):\n",
    "        temp = char_to_int[df_test_split.loc[j,i]]\n",
    "        df_test_onehot[j, i*NUM_MUTATORS + temp] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#lets norm this shit (this is only necessary if we use the 4D representation\n",
    "#df_nn = (df+1)/21\n",
    "#df_cock_nn = (df_cock+1)/21\n",
    "\n",
    "#for the binary version use this:\n",
    "df_train_onehot_nn = df_train_onehot\n",
    "df_test_onehot_nn = df_test_onehot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tensorboard = True\n",
    "\n",
    "if show_tensorboard:\n",
    "    # Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard\n",
    "    #%reload_ext tensorboard\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss_simple(y_true, y_pred):\n",
    "    loss_f1 = f1_score(y_true, y_pred)\n",
    "    return loss_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' class f1_loss(Layer):\\n\\n    def __init__(self, rate=1e-2):\\n        super(f1_loss, self).__init__()\\n        self.rate = rate\\n\\n    def custom_loss(self, y_true, y_pred):\\n        self.add_loss(self.rate * f1_score(y_true, y_pred))\\n        return  '"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "\"\"\" class f1_loss(Layer):\n",
    "\n",
    "    def __init__(self, rate=1e-2):\n",
    "        super(f1_loss, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "        self.add_loss(self.rate * f1_score(y_true, y_pred))\n",
    "        return  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some callbacks to stop overfitting\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when val_loss is no longer improving\n",
    "        monitor=\"val_f1_m\",\n",
    "        # Take the minimum of val_loss as a guideline.\n",
    "        mode=\"max\",\n",
    "        # No longer improving\" being further defined as \"for at least 50 epochs.\n",
    "        patience=300,\n",
    "        # Since we have such a large paitience we restore back to the best weights after a long waittime.\n",
    "        restore_best_weights = True,\n",
    "        verbose = 1,\n",
    "    )\n",
    "]\n",
    "\n",
    "## Some \n",
    "        #log_dir=log_dir,\n",
    "        #histogram_freq=1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4213 are a 1 from the label array.\n107787 are a 0 that is  96.23839285714286 %.\n{0: 0.5195431731099298, 1: 53.16876335153098}\n"
     ]
    }
   ],
   "source": [
    "number_1 = np.count_nonzero(labels)\n",
    "print(number_1 , 'are a 1 from the label array.')\n",
    "print(DF_TRAIN_SIZE - number_1, 'are a 0 that is ' , 100*(1-1/float(DF_TRAIN_SIZE)*number_1), '%.')\n",
    "\n",
    "#Thus we need to ajust the weights used for punishment of the neural net. Or else a output of all 0 will lead to a \"success\" of 96%.\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(labels), labels)\n",
    "#Now we actualy want to give an increased weight to the ones. Here with 4 times more important.\n",
    "\n",
    "class_weights[1] *= 4\n",
    "class_weights = {i : class_weights[i] for i in range(len(np.unique(labels)))}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "88/88 - 9s - loss: 0.8062 - acc: 0.5690 - f1_m: 0.1431 - precision_m: 0.0776 - recall_m: 0.9458 - val_loss: 0.4193 - val_acc: 0.9633 - val_f1_m: 0.0776 - val_precision_m: 0.6424 - val_recall_m: 0.0420\n",
      "Epoch 2/1000\n",
      "88/88 - 3s - loss: 0.4551 - acc: 0.7460 - f1_m: 0.2306 - precision_m: 0.1312 - recall_m: 0.9920 - val_loss: 0.1960 - val_acc: 0.9668 - val_f1_m: 0.2781 - val_precision_m: 0.7600 - val_recall_m: 0.1732\n",
      "Epoch 3/1000\n",
      "88/88 - 3s - loss: 0.3421 - acc: 0.8449 - f1_m: 0.3266 - precision_m: 0.1967 - recall_m: 0.9938 - val_loss: 0.1304 - val_acc: 0.9764 - val_f1_m: 0.6418 - val_precision_m: 0.7468 - val_recall_m: 0.5677\n",
      "Epoch 4/1000\n",
      "88/88 - 3s - loss: 0.2764 - acc: 0.8898 - f1_m: 0.4036 - precision_m: 0.2549 - recall_m: 0.9924 - val_loss: 0.1055 - val_acc: 0.9734 - val_f1_m: 0.7058 - val_precision_m: 0.6016 - val_recall_m: 0.8600\n",
      "Epoch 5/1000\n",
      "88/88 - 3s - loss: 0.2331 - acc: 0.9064 - f1_m: 0.4434 - precision_m: 0.2874 - recall_m: 0.9940 - val_loss: 0.1179 - val_acc: 0.9654 - val_f1_m: 0.6698 - val_precision_m: 0.5209 - val_recall_m: 0.9469\n",
      "Epoch 6/1000\n",
      "88/88 - 3s - loss: 0.2029 - acc: 0.9211 - f1_m: 0.4851 - precision_m: 0.3233 - recall_m: 0.9942 - val_loss: 0.1557 - val_acc: 0.9502 - val_f1_m: 0.5928 - val_precision_m: 0.4274 - val_recall_m: 0.9761\n",
      "Epoch 7/1000\n",
      "88/88 - 3s - loss: 0.1780 - acc: 0.9308 - f1_m: 0.5181 - precision_m: 0.3524 - recall_m: 0.9962 - val_loss: 0.1773 - val_acc: 0.9476 - val_f1_m: 0.5820 - val_precision_m: 0.4155 - val_recall_m: 0.9809\n",
      "Epoch 8/1000\n",
      "88/88 - 3s - loss: 0.1549 - acc: 0.9398 - f1_m: 0.5537 - precision_m: 0.3861 - recall_m: 0.9963 - val_loss: 0.1365 - val_acc: 0.9575 - val_f1_m: 0.6328 - val_precision_m: 0.4683 - val_recall_m: 0.9829\n",
      "Epoch 9/1000\n",
      "88/88 - 3s - loss: 0.1407 - acc: 0.9478 - f1_m: 0.5865 - precision_m: 0.4185 - recall_m: 0.9969 - val_loss: 0.2029 - val_acc: 0.9471 - val_f1_m: 0.5804 - val_precision_m: 0.4129 - val_recall_m: 0.9850\n",
      "Epoch 10/1000\n",
      "88/88 - 3s - loss: 0.1251 - acc: 0.9522 - f1_m: 0.6088 - precision_m: 0.4415 - recall_m: 0.9968 - val_loss: 0.1587 - val_acc: 0.9576 - val_f1_m: 0.6330 - val_precision_m: 0.4681 - val_recall_m: 0.9836\n",
      "Epoch 11/1000\n",
      "88/88 - 3s - loss: 0.1122 - acc: 0.9573 - f1_m: 0.6348 - precision_m: 0.4685 - recall_m: 0.9987 - val_loss: 0.1230 - val_acc: 0.9639 - val_f1_m: 0.6697 - val_precision_m: 0.5098 - val_recall_m: 0.9825\n",
      "Epoch 12/1000\n",
      "88/88 - 3s - loss: 0.1038 - acc: 0.9603 - f1_m: 0.6524 - precision_m: 0.4876 - recall_m: 0.9977 - val_loss: 0.1167 - val_acc: 0.9671 - val_f1_m: 0.6887 - val_precision_m: 0.5330 - val_recall_m: 0.9808\n",
      "Epoch 13/1000\n",
      "88/88 - 3s - loss: 0.1008 - acc: 0.9617 - f1_m: 0.6607 - precision_m: 0.4976 - recall_m: 0.9976 - val_loss: 0.1536 - val_acc: 0.9567 - val_f1_m: 0.6274 - val_precision_m: 0.4628 - val_recall_m: 0.9802\n",
      "Epoch 14/1000\n",
      "88/88 - 3s - loss: 0.0966 - acc: 0.9618 - f1_m: 0.6609 - precision_m: 0.4969 - recall_m: 0.9984 - val_loss: 0.1471 - val_acc: 0.9592 - val_f1_m: 0.6413 - val_precision_m: 0.4784 - val_recall_m: 0.9827\n",
      "Epoch 15/1000\n",
      "88/88 - 2s - loss: 0.0862 - acc: 0.9661 - f1_m: 0.6859 - precision_m: 0.5266 - recall_m: 0.9979 - val_loss: 0.1164 - val_acc: 0.9661 - val_f1_m: 0.6824 - val_precision_m: 0.5260 - val_recall_m: 0.9785\n",
      "Epoch 16/1000\n",
      "88/88 - 3s - loss: 0.0909 - acc: 0.9648 - f1_m: 0.6784 - precision_m: 0.5176 - recall_m: 0.9977 - val_loss: 0.1117 - val_acc: 0.9675 - val_f1_m: 0.6898 - val_precision_m: 0.5363 - val_recall_m: 0.9721\n",
      "Epoch 17/1000\n",
      "88/88 - 3s - loss: 0.0832 - acc: 0.9670 - f1_m: 0.6918 - precision_m: 0.5335 - recall_m: 0.9974 - val_loss: 0.1046 - val_acc: 0.9714 - val_f1_m: 0.7185 - val_precision_m: 0.5695 - val_recall_m: 0.9804\n",
      "Epoch 18/1000\n",
      "88/88 - 3s - loss: 0.0765 - acc: 0.9707 - f1_m: 0.7169 - precision_m: 0.5627 - recall_m: 0.9983 - val_loss: 0.1059 - val_acc: 0.9711 - val_f1_m: 0.7158 - val_precision_m: 0.5659 - val_recall_m: 0.9783\n",
      "Epoch 19/1000\n",
      "88/88 - 3s - loss: 0.0972 - acc: 0.9630 - f1_m: 0.6697 - precision_m: 0.5110 - recall_m: 0.9958 - val_loss: 0.1887 - val_acc: 0.9476 - val_f1_m: 0.5858 - val_precision_m: 0.4170 - val_recall_m: 0.9944\n",
      "Epoch 20/1000\n",
      "88/88 - 3s - loss: 0.0826 - acc: 0.9673 - f1_m: 0.6959 - precision_m: 0.5391 - recall_m: 0.9982 - val_loss: 0.1311 - val_acc: 0.9671 - val_f1_m: 0.6890 - val_precision_m: 0.5326 - val_recall_m: 0.9821\n",
      "Epoch 21/1000\n",
      "88/88 - 3s - loss: 0.0743 - acc: 0.9708 - f1_m: 0.7186 - precision_m: 0.5644 - recall_m: 0.9989 - val_loss: 0.0999 - val_acc: 0.9721 - val_f1_m: 0.7212 - val_precision_m: 0.5749 - val_recall_m: 0.9736\n",
      "Epoch 22/1000\n",
      "88/88 - 2s - loss: 0.0705 - acc: 0.9739 - f1_m: 0.7397 - precision_m: 0.5912 - recall_m: 0.9986 - val_loss: 0.1044 - val_acc: 0.9737 - val_f1_m: 0.7334 - val_precision_m: 0.5905 - val_recall_m: 0.9742\n",
      "Epoch 23/1000\n",
      "88/88 - 2s - loss: 0.0662 - acc: 0.9752 - f1_m: 0.7481 - precision_m: 0.6017 - recall_m: 0.9990 - val_loss: 0.1011 - val_acc: 0.9730 - val_f1_m: 0.7303 - val_precision_m: 0.5827 - val_recall_m: 0.9842\n",
      "Epoch 24/1000\n",
      "88/88 - 2s - loss: 0.0712 - acc: 0.9724 - f1_m: 0.7300 - precision_m: 0.5793 - recall_m: 0.9983 - val_loss: 0.1343 - val_acc: 0.9655 - val_f1_m: 0.6785 - val_precision_m: 0.5202 - val_recall_m: 0.9814\n",
      "Epoch 25/1000\n",
      "88/88 - 2s - loss: 0.0626 - acc: 0.9754 - f1_m: 0.7507 - precision_m: 0.6053 - recall_m: 0.9989 - val_loss: 0.1154 - val_acc: 0.9702 - val_f1_m: 0.7095 - val_precision_m: 0.5582 - val_recall_m: 0.9792\n",
      "Epoch 26/1000\n",
      "88/88 - 2s - loss: 0.0584 - acc: 0.9783 - f1_m: 0.7734 - precision_m: 0.6345 - recall_m: 0.9992 - val_loss: 0.0950 - val_acc: 0.9764 - val_f1_m: 0.7533 - val_precision_m: 0.6169 - val_recall_m: 0.9719\n",
      "Epoch 27/1000\n",
      "88/88 - 2s - loss: 0.0550 - acc: 0.9788 - f1_m: 0.7776 - precision_m: 0.6409 - recall_m: 0.9987 - val_loss: 0.0874 - val_acc: 0.9775 - val_f1_m: 0.7628 - val_precision_m: 0.6307 - val_recall_m: 0.9718\n",
      "Epoch 28/1000\n",
      "88/88 - 3s - loss: 0.0557 - acc: 0.9797 - f1_m: 0.7837 - precision_m: 0.6499 - recall_m: 0.9987 - val_loss: 0.0943 - val_acc: 0.9756 - val_f1_m: 0.7468 - val_precision_m: 0.6089 - val_recall_m: 0.9716\n",
      "Epoch 29/1000\n",
      "88/88 - 2s - loss: 0.0535 - acc: 0.9805 - f1_m: 0.7918 - precision_m: 0.6601 - recall_m: 0.9989 - val_loss: 0.1164 - val_acc: 0.9702 - val_f1_m: 0.7087 - val_precision_m: 0.5583 - val_recall_m: 0.9764\n",
      "Epoch 30/1000\n",
      "88/88 - 3s - loss: 0.0555 - acc: 0.9782 - f1_m: 0.7727 - precision_m: 0.6336 - recall_m: 0.9992 - val_loss: 0.0864 - val_acc: 0.9773 - val_f1_m: 0.7601 - val_precision_m: 0.6271 - val_recall_m: 0.9698\n",
      "Epoch 31/1000\n",
      "88/88 - 2s - loss: 0.0485 - acc: 0.9818 - f1_m: 0.8017 - precision_m: 0.6735 - recall_m: 0.9995 - val_loss: 0.0797 - val_acc: 0.9796 - val_f1_m: 0.7812 - val_precision_m: 0.6526 - val_recall_m: 0.9777\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c4a786255267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#fit the network to (for now the un-sparse matrix)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mneuralNetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train_onehot_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#version without loss monitoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lets construct the neural net:\n",
    "neuralNetwork = Sequential()\n",
    "neuralNetwork.add(Dense(128, activation='relu', input_dim=NUM_MUTATORS * 4))\n",
    "neuralNetwork.add(BatchNormalization())\n",
    "neuralNetwork.add(Dense(128, activation='relu'))\n",
    "neuralNetwork.add(BatchNormalization())\n",
    "neuralNetwork.add(Dropout(0.2))\n",
    "neuralNetwork.add(Dense(128, activation='relu'))\n",
    "neuralNetwork.add(BatchNormalization())\n",
    "neuralNetwork.add(Dropout(0.2))\n",
    "neuralNetwork.add(Dense(128, activation='relu'))\n",
    "neuralNetwork.add(BatchNormalization())\n",
    "neuralNetwork.add(Dropout(0.2))\n",
    "neuralNetwork.add(Dense(128, activation='relu'))\n",
    "neuralNetwork.add(BatchNormalization())\n",
    "neuralNetwork.add(Dropout(0.2))\n",
    "neuralNetwork.add(Dense(1, activation='sigmoid'))\n",
    "#neuralNetwork.add(BatchNormalization())\n",
    " \n",
    "neuralNetwork.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "#fit the network to (for now the un-sparse matrix)\n",
    "neuralNetwork.fit(df_train_onehot_nn, labels, epochs=1000, batch_size=1024, verbose=2, callbacks= [callbacks, tensorboard_callback], validation_split = 0.2, class_weight=class_weights)\n",
    "\n",
    "#version without loss monitoring\n",
    "\"\"\" if show_tensorboard:\n",
    "    neuralNetwork.fit(df_train_onehot_nn, labels, epochs=1000, batch_size=1024, verbose=1, callbacks = tensorboard_callback, validation_split = 0.2, class_weight=class_weights)\n",
    "else: neuralNetwork.fit(df_train_onehot_nn, labels, epochs=1000, batch_size=1024, verbose=1, validation_split = 0.2, class_weight=class_weights) \"\"\"\n",
    "#evaluation of the network prediction\n",
    "predict_test_nn = neuralNetwork.predict(df_test_onehot_nn)\n",
    "predict_train_nn = neuralNetwork.predict(df_train_onehot_nn)\n",
    "print(predict_test_nn)\n",
    "print(predict_train_nn)\n",
    "predict_test_nn = (predict_test_nn >= 0.5)\n",
    "\n",
    "\n",
    "neuralNetwork.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n2.907142e-20\nactual labels: 4213\npredicted labels: 4283\nthe f1 score is: 0.9724576271186441\n"
     ]
    }
   ],
   "source": [
    "print(predict_train_nn.max())\n",
    "print(predict_train_nn.min())\n",
    "\n",
    "print(\"actual labels:\", np.sum(labels))\n",
    "print(\"predicted labels:\", np.sum(predict_train_nn >0.5))\n",
    "print(\"the f1 score is:\", f1_score(labels.astype('bool'), (predict_train_nn >=0.5).astype('bool')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% evaluation of the NN on the train data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "predict_test_nn = pd.DataFrame(predict_test_nn.astype('int'))\n",
    "predict_test_nn.to_csv('predictions.csv', header = False, index = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}